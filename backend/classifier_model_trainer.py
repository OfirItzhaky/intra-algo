import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb
import xgboost as xgb
from tqdm import tqdm

class ClassifierModelTrainer:
    """
    A class to train and evaluate classifiers for predicting 'good bar' classifications.
    Supports RandomForest, LightGBM, and XGBoost.
    """

    def __init__(self):
        """Initializes the ClassifierModelTrainer."""

        self.rf_results = None
        self.lgbm_results = None
        self.xgb_results = None

        print("âœ… ClassifierModelTrainer initialized!")

    def train_random_forest(self, X_train, y_train, X_test, y_test):
        """
        Trains and evaluates a RandomForestClassifier.

        Parameters:
            X_train, y_train: Training dataset
            X_test, y_test: Test dataset

        Returns:
            dict: Contains evaluation metrics, feature importance, predictions, and trained model.
        """
        print("\nðŸš€ Training RandomForest...")

        # âœ… Define the model
        rf_model = RandomForestClassifier(
            class_weight="balanced",
            max_depth=10,
            min_samples_leaf=5,
            min_samples_split=10,
            n_estimators=100,
            random_state=42
        )

        # âœ… Train the model
        rf_model.fit(X_train, y_train)
        print("âœ… RandomForest training complete.")

        # âœ… Predict on test data
        predictions = rf_model.predict(X_test)

        # âœ… Evaluate performance
        evaluation_metrics = classification_report(y_test, predictions, output_dict=True)
        accuracy = accuracy_score(y_test, predictions)

        print("\nðŸ“Š RandomForest Evaluation:")
        print(classification_report(y_test, predictions))
        print(f"\nðŸŽ¯ RandomForest Accuracy: {accuracy:.4f}")

        # âœ… Feature Importance
        importances = rf_model.feature_importances_
        feature_importance_df = pd.DataFrame({"Feature": X_train.columns, "Importance": importances}).sort_values(
            by="Importance", ascending=False
        )
        print("\nðŸ“Š Top 10 Feature Importances:\n", feature_importance_df.head(10))

        return {
            "model": rf_model,
            "accuracy": accuracy,
            "evaluation_metrics": evaluation_metrics,
            "feature_importance": feature_importance_df,
            "predictions": predictions
        }

    def train_lightgbm(self, X_train, y_train, X_test, y_test):
        """
        Trains and evaluates a LightGBM classifier.

        Parameters:
            X_train, y_train: Training dataset
            X_test, y_test: Test dataset

        Returns:
            dict: Contains evaluation metrics, feature importance, predictions, and trained model.
        """
        print("\nðŸš€ Training LightGBM...")

        # âœ… Define LightGBM parameters
        lightgbm_params = {
            "objective": "binary",
            "metric": "binary_error",
            "boosting_type": "gbdt",
            "learning_rate": 0.05,
            "num_leaves": 31,
            "max_depth": 10,
            "min_data_in_leaf": 10,
            "verbose": -1
        }

        # âœ… Prepare dataset for LightGBM
        lgb_train = lgb.Dataset(X_train, label=y_train)
        lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)

        # âœ… Training LightGBM with progress bar
        with tqdm(total=100, desc="LightGBM Training Progress") as pbar:
            def update_progress(env):
                pbar.update()

            lgb_model = lgb.train(lightgbm_params, lgb_train, valid_sets=[lgb_test], callbacks=[update_progress])

        # âœ… Predict & Evaluate LightGBM
        probabilities = lgb_model.predict(X_test)
        predictions = (probabilities >= 0.5).astype(int)
        accuracy = accuracy_score(y_test, predictions)

        print("\nðŸ“Š LightGBM Evaluation:")
        print(classification_report(y_test, predictions))
        print(f"\nðŸŽ¯ LightGBM Accuracy: {accuracy:.4f}")

        # âœ… Feature Importance
        feature_importance_df = pd.DataFrame({"Feature": X_train.columns, "Importance": lgb_model.feature_importance()}).sort_values(
            by="Importance", ascending=False
        )
        print("\nðŸ“Š Top 10 Feature Importances:\n", feature_importance_df.head(10))

        return {
            "model": lgb_model,
            "accuracy": accuracy,
            "evaluation_metrics": classification_report(y_test, predictions, output_dict=True),
            "feature_importance": feature_importance_df,
            "predictions": predictions
        }

    def train_xgboost(self, X_train, y_train, X_test, y_test):
        """
        Trains and evaluates an XGBoost classifier.

        Parameters:
            X_train, y_train: Training dataset
            X_test, y_test: Test dataset

        Returns:
            dict: Contains evaluation metrics, feature importance, predictions, and trained model.
        """
        print("\nðŸš€ Training XGBoost...")

        # âœ… Define XGBoost parameters
        xgboost_params = {
            "objective": "binary:logistic",
            "eval_metric": "logloss",
            "learning_rate": 0.05,
            "max_depth": 10,
            "n_estimators": 100,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "verbosity": 1
        }

        # âœ… Train XGBoost with progress bar
        xgb_model = xgb.XGBClassifier(**xgboost_params)

        with tqdm(total=100, desc="XGBoost Training Progress") as pbar:
            xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)
            pbar.update(100)  # Ensure full progress bar update

        # âœ… Predict & Evaluate XGBoost
        probabilities = xgb_model.predict_proba(X_test)[:, 1]
        predictions = (probabilities >= 0.5).astype(int)
        accuracy = accuracy_score(y_test, predictions)

        print("\nðŸ“Š XGBoost Evaluation:")
        print(classification_report(y_test, predictions))
        print(f"\nðŸŽ¯ XGBoost Accuracy: {accuracy:.4f}")

        # âœ… Feature Importance
        feature_importance_df = pd.DataFrame({"Feature": X_train.columns, "Importance": xgb_model.feature_importances_}).sort_values(
            by="Importance", ascending=False
        )
        print("\nðŸ“Š Top 10 Feature Importances:\n", feature_importance_df.head(10))

        return {
            "model": xgb_model,
            "accuracy": accuracy,
            "evaluation_metrics": classification_report(y_test, predictions, output_dict=True),
            "feature_importance": feature_importance_df,
            "predictions": predictions
        }
